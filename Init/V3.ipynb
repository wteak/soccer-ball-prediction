{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed411f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [Physics Enhanced] LSTM with Action-ID Sorting ---\n",
      "1. 데이터 로드...\n",
      " -> 시퀀스 변환 및 물리 피처 적용 중... (Train)\n",
      "2. 학습 시작 (Epochs: 50)...\n",
      "   Epoch [5/50], Loss: 194.8685\n",
      "   Epoch [10/50], Loss: 180.7657\n",
      "   Epoch [15/50], Loss: 171.1107\n",
      "   Epoch [20/50], Loss: 152.0418\n",
      "   Epoch [25/50], Loss: 121.1683\n",
      "   Epoch [30/50], Loss: 91.6479\n",
      "   Epoch [35/50], Loss: 70.8074\n",
      "   Epoch [40/50], Loss: 56.8144\n",
      "   Epoch [45/50], Loss: 46.4760\n",
      "   Epoch [50/50], Loss: 41.7839\n",
      "3. Test 예측 및 병합...\n",
      " -> 시퀀스 변환 및 물리 피처 적용 중... (Test)\n",
      "\n",
      "[성공] 'submission_physics.csv' 생성 완료.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd#버전2에서 각 이벤트마다 물리적 특징 추가 매핑 및 action_id를 기준으로 정렬(시간순서 다를수있다고했기에)\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"--- [Physics Enhanced] LSTM with Action-ID Sorting ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# [1] 설정\n",
    "# ==============================================================================\n",
    "TRAIN_FILE = 'train.csv'\n",
    "TEST_FOLDER = 'test/'\n",
    "SAMPLE_FILE = 'sample_submission.csv'\n",
    "OUTPUT_FILE = 'submission_physics.csv'\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_DIM = 256\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 50\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if not os.path.exists(SAMPLE_FILE):\n",
    "    raise FileNotFoundError(f\"'{SAMPLE_FILE}' 파일이 없습니다.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# [2] 핵심 구현 1: 물리적 특징 매핑 (Physics Embedding)\n",
    "# ==============================================================================\n",
    "def apply_physics_features(df):\n",
    "    \"\"\"\n",
    "    단순한 Label Encoding 대신, 이벤트의 물리적 성격을 수치화하여 매핑합니다.\n",
    "    \"\"\"\n",
    "    # 1. 속도 점수 (0~1): 공이 얼마나 빠르게 이동하는 이벤트인가?\n",
    "    # Pass/Shot/Clearance 등은 빠르고, Duel/Touch 등은 느림\n",
    "    speed_map = {\n",
    "        'Pass': 0.9, 'Shot': 1.0, 'Clearance': 0.9, 'Cross': 0.9,\n",
    "        'Carry': 0.4, 'Dribble': 0.5, \n",
    "        'Duel': 0.1, 'Foul': 0.0, 'Interception': 0.2, 'Block': 0.1,\n",
    "        'Save': 0.1, 'Take On': 0.5, 'Ball Recovery': 0.3\n",
    "    }\n",
    "    \n",
    "    # 2. 소유권 점수 (0~1): 선수가 공을 얼마나 통제하고 있는가?\n",
    "    # Carry/Dribble은 통제 중(1), Pass/Shot은 통제 벗어남(0), 경합은 반반(0.5)\n",
    "    control_map = {\n",
    "        'Carry': 1.0, 'Dribble': 1.0, 'Take On': 1.0, 'Ball Touch': 1.0,\n",
    "        'Pass': 0.0, 'Shot': 0.0, 'Clearance': 0.0, 'Cross': 0.0,\n",
    "        'Duel': 0.5, 'Interception': 0.5, 'Block': 0.5, 'Foul': 0.0\n",
    "    }\n",
    "    \n",
    "    # 3. 신체 접촉/충돌 가능성 (0~1)\n",
    "    # Duel/Foul/Tackle은 높음\n",
    "    contact_map = {\n",
    "        'Duel': 1.0, 'Foul': 1.0, 'Tackle': 1.0, 'Aerial Duel': 1.0,\n",
    "        'Block': 0.8, 'Interception': 0.6,\n",
    "        'Pass': 0.1, 'Carry': 0.2, 'Shot': 0.1\n",
    "    }\n",
    "\n",
    "    # 매핑 적용 (없는 키는 평균값 0.5 또는 0.0 처리)\n",
    "    df['physics_speed'] = df['type_name'].map(speed_map).fillna(0.4)\n",
    "    df['physics_control'] = df['type_name'].map(control_map).fillna(0.5)\n",
    "    df['physics_contact'] = df['type_name'].map(contact_map).fillna(0.1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ==============================================================================\n",
    "# [3] 데이터 전처리 및 시퀀스 생성\n",
    "# ==============================================================================\n",
    "def create_sequences(df, scaler=None, is_train=True):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # --- [핵심 구현 2] 정렬 순서 보장 ---\n",
    "    # 데이터 설명서: \"action_id와 time_seconds 순서가 불일치할 수 있음\"\n",
    "    # -> 따라서 time_seconds가 아니라 action_id를 최우선 정렬 기준으로 삼아야 함.\n",
    "    # -> game_id -> episode_id -> action_id 순으로 정렬해야 인과관계가 깨지지 않음.\n",
    "    df = df.sort_values(['game_id', 'episode_id', 'action_id'])\n",
    "    \n",
    "    # 1. 물리적 특징 적용\n",
    "    df = apply_physics_features(df)\n",
    "    \n",
    "    # 2. 기본 거리/각도 계산\n",
    "    df['dist_to_goal'] = np.sqrt((105 - df['start_x'])**2 + (34 - df['start_y'])**2)\n",
    "    df['angle_to_goal'] = np.arctan2((34 - df['start_y']), (105 - df['start_x']))\n",
    "    \n",
    "    # 3. 시간 차이 (Delta Time) 계산\n",
    "    # action_id 순으로 정렬했으므로, 이전 행동과의 시간 차이를 구함\n",
    "    # game_episode 키 생성\n",
    "    if 'game_episode' not in df.columns:\n",
    "        df['game_episode'] = df['game_id'].astype(str) + '_' + df['episode_id'].astype(str)\n",
    "        \n",
    "    df['time_delta'] = df.groupby('game_episode')['time_seconds'].diff().fillna(0)\n",
    "    \n",
    "    # 혹시 action_id 순서인데 시간이 역행하는 경우(데이터 오류) 음수 방지\n",
    "    df['time_delta'] = df['time_delta'].apply(lambda x: x if x >= 0 else 0)\n",
    "\n",
    "    # 4. 사용할 피처 선정\n",
    "    # type_name(LabelEncoding) 대신 physics_features 사용\n",
    "    feature_cols = [\n",
    "        'start_x', 'start_y', \n",
    "        'dist_to_goal', 'angle_to_goal', \n",
    "        'time_delta', \n",
    "        'physics_speed', 'physics_control', 'physics_contact'\n",
    "    ]\n",
    "    \n",
    "    # 5. 스케일링\n",
    "    if is_train:\n",
    "        scaler = StandardScaler()\n",
    "        df[feature_cols] = scaler.fit_transform(df[feature_cols].values)\n",
    "    else:\n",
    "        df[feature_cols] = scaler.transform(df[feature_cols].values)\n",
    "\n",
    "    # 6. 시퀀스 변환\n",
    "    grouped = df.groupby(['game_id', 'episode_id']) # 이미 action_id 정렬됨\n",
    "    \n",
    "    sequences = []\n",
    "    targets = []\n",
    "    keys = []\n",
    "    \n",
    "    print(f\" -> 시퀀스 변환 및 물리 피처 적용 ({'Train' if is_train else 'Test'})\")\n",
    "    \n",
    "    for (game_id, episode_id), group in grouped:\n",
    "        # 입력 시퀀스\n",
    "        seq_tensor = torch.tensor(group[feature_cols].values, dtype=torch.float32)\n",
    "        sequences.append(seq_tensor)\n",
    "        keys.append((game_id, episode_id))\n",
    "        \n",
    "        # 정답 (Train only)\n",
    "        if is_train:\n",
    "            target = group[['end_x', 'end_y']].iloc[-1].values\n",
    "            targets.append(torch.tensor(target, dtype=torch.float32))\n",
    "            \n",
    "    return sequences, targets, keys, scaler, len(feature_cols)\n",
    "\n",
    "# ==============================================================================\n",
    "# [4] Dataset & LSTM Model (이전과 동일 구조)\n",
    "# ==============================================================================\n",
    "class SoccerSeqDataset(Dataset):\n",
    "    def __init__(self, sequences, targets=None):\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "    def __len__(self): return len(self.sequences)\n",
    "    def __getitem__(self, idx):\n",
    "        if self.targets: return self.sequences[idx], self.targets[idx]\n",
    "        return self.sequences[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    has_target = isinstance(batch[0], tuple)\n",
    "    if has_target:\n",
    "        sequences = [item[0] for item in batch]\n",
    "        targets = torch.stack([item[1] for item in batch])\n",
    "    else:\n",
    "        sequences = batch\n",
    "        targets = None\n",
    "    lengths = torch.tensor([len(seq) for seq in sequences])\n",
    "    padded_seqs = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    return padded_seqs, targets, lengths\n",
    "\n",
    "class SoccerLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout):\n",
    "        super(SoccerLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 2)\n",
    "        )\n",
    "    def forward(self, x, lengths):\n",
    "        packed_input = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_input)\n",
    "        last_hidden = hidden[-1]\n",
    "        out = self.fc(last_hidden)\n",
    "        return out\n",
    "\n",
    "# ==============================================================================\n",
    "# [5] 실행 파이프라인\n",
    "# ==============================================================================\n",
    "print(\"1. 데이터 로드...\")\n",
    "df_train = pd.read_csv(TRAIN_FILE)\n",
    "\n",
    "# Train 시퀀스 생성\n",
    "train_seqs, train_targets, _, scaler, input_dim = create_sequences(df_train, is_train=True)\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = SoccerSeqDataset(train_seqs, train_targets)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# 모델 초기화\n",
    "model = SoccerLSTM(input_dim, HIDDEN_DIM, NUM_LAYERS, DROPOUT).to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"2. 학습 시작 (Epochs: {EPOCHS})...\")\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for padded_seqs, targets, lengths in train_loader:\n",
    "        padded_seqs, targets = padded_seqs.to(DEVICE), targets.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(padded_seqs, lengths)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"   Epoch [{epoch+1}/{EPOCHS}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"3. Test 예측 및 병합...\")\n",
    "test_files = [os.path.join(r, f) for r, d, fs in os.walk(TEST_FOLDER) for f in fs if f.endswith(\".csv\")]\n",
    "df_test = pd.concat([pd.read_csv(f) for f in test_files], ignore_index=True)\n",
    "\n",
    "# Test 시퀀스 생성 (정렬 및 Physics 적용됨)\n",
    "test_seqs, _, test_keys, _, _ = create_sequences(df_test, scaler=scaler, is_train=False)\n",
    "\n",
    "test_dataset = SoccerSeqDataset(test_seqs)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for padded_seqs, _, lengths in test_loader:\n",
    "        padded_seqs = padded_seqs.to(DEVICE)\n",
    "        outputs = model(padded_seqs, lengths)\n",
    "        all_preds.append(outputs.cpu().numpy())\n",
    "\n",
    "predictions = np.vstack(all_preds)\n",
    "pred_x = np.clip(predictions[:, 0], 0, 105.0)\n",
    "pred_y = np.clip(predictions[:, 1], 0, 68.0)\n",
    "\n",
    "# 결과 매칭\n",
    "result_df = pd.DataFrame(test_keys, columns=['game_id', 'episode_id'])\n",
    "result_df['pred_end_x'] = pred_x\n",
    "result_df['pred_end_y'] = pred_y\n",
    "\n",
    "# Sample Submission 병합\n",
    "submission = pd.read_csv(SAMPLE_FILE)\n",
    "submission['game_id'] = submission['game_episode'].apply(lambda x: int(x.split('_')[0]))\n",
    "submission['episode_id'] = submission['game_episode'].apply(lambda x: int(x.split('_')[1]))\n",
    "\n",
    "final_df = pd.merge(submission, result_df, on=['game_id', 'episode_id'], how='left')\n",
    "final_df['end_x'] = final_df['pred_end_x']\n",
    "final_df['end_y'] = final_df['pred_end_y']\n",
    "final_df = final_df.fillna(0)\n",
    "\n",
    "final_df[['game_episode', 'end_x', 'end_y']].to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"\\n[성공] '{OUTPUT_FILE}' 생성 완료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
