{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86f6f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [High Accuracy] LSTM Sequence Model ---\n",
      " -> 사용 장치: cpu\n",
      "1. 데이터 로드 및 시퀀스 변환...\n",
      " -> 시퀀스 변환 중... (Train)\n",
      "2. 학습 시작 (Epochs: 50)...\n",
      "   Epoch [5/50], Loss: 192.5835\n",
      "   Epoch [10/50], Loss: 177.9152\n",
      "   Epoch [15/50], Loss: 168.7846\n",
      "   Epoch [20/50], Loss: 152.9207\n",
      "   Epoch [25/50], Loss: 127.3425\n",
      "   Epoch [30/50], Loss: 97.6084\n",
      "   Epoch [35/50], Loss: 75.6162\n",
      "   Epoch [40/50], Loss: 62.3177\n",
      "   Epoch [45/50], Loss: 50.3468\n",
      "   Epoch [50/50], Loss: 43.1649\n",
      "3. Test 데이터 처리...\n",
      " -> 시퀀스 변환 중... (Test)\n",
      "4. 예측 수행...\n",
      "5. Sample Submission 파일 병합...\n",
      "\n",
      "[성공] 'submission_lstm.csv' 생성 완료.\n",
      " -> 데이터 확인:\n",
      "  game_episode      end_x      end_y\n",
      "0     153363_1  64.134933  11.696858\n",
      "1     153363_2  33.889278  58.680855\n",
      "2     153363_6  61.135262  61.424477\n",
      "3     153363_7  74.947136  20.479153\n",
      "4     153363_8  79.275505   4.700223\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd#버전1에서LSTM로 변경 \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"--- [High Accuracy] LSTM Sequence Model ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# [1] 설정 및 하이퍼파라미터\n",
    "# ==============================================================================\n",
    "TRAIN_FILE = 'train.csv'\n",
    "TEST_FOLDER = 'test/'\n",
    "SAMPLE_FILE = 'sample_submission.csv'\n",
    "OUTPUT_FILE = 'submission_lstm.csv'\n",
    "\n",
    "# 하이퍼파라미터 (정확도를 위해 튜닝 가능)\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_DIM = 256  # 은닉층 크기를 키움\n",
    "NUM_LAYERS = 2    # 층을 쌓아 복잡한 패턴 학습\n",
    "DROPOUT = 0.3\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 50       # 충분한 학습\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if not os.path.exists(SAMPLE_FILE):\n",
    "    raise FileNotFoundError(f\"'{SAMPLE_FILE}' 파일이 없습니다.\")\n",
    "\n",
    "print(f\" -> 사용 장치: {DEVICE}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# [2] 데이터 전처리: 시퀀스 생성 함수\n",
    "# ==============================================================================\n",
    "def create_sequences(df, scaler=None, encoders=None, is_train=True):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. 기본 피처 생성\n",
    "    df['dist_to_goal'] = np.sqrt((105 - df['start_x'])**2 + (34 - df['start_y'])**2)\n",
    "    df['angle_to_goal'] = np.arctan2((34 - df['start_y']), (105 - df['start_x']))\n",
    "    \n",
    "    # 시간 차이 (Delta Time)\n",
    "    # game_episode 키 생성 (그룹핑용)\n",
    "    if 'game_episode' not in df.columns:\n",
    "        df['game_episode'] = df['game_id'].astype(str) + '_' + df['episode_id'].astype(str)\n",
    "        \n",
    "    df['time_delta'] = df.groupby('game_episode')['time_seconds'].diff().fillna(0)\n",
    "\n",
    "    # 2. 범주형 인코딩\n",
    "    cat_cols = ['type_name', 'result_name']\n",
    "    if is_train:\n",
    "        encoders = {}\n",
    "        for col in cat_cols:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = df[col].fillna('Unknown').astype(str)\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "            encoders[col] = le\n",
    "    else:\n",
    "        for col in cat_cols:\n",
    "            df[col] = df[col].fillna('Unknown').astype(str)\n",
    "            le = encoders[col]\n",
    "            df[col] = df[col].map(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\n",
    "\n",
    "    # 3. 스케일링 (LSTM은 스케일에 매우 민감함)\n",
    "    # 사용할 피처 정의\n",
    "    feature_cols = ['start_x', 'start_y', 'dist_to_goal', 'angle_to_goal', 'time_delta', 'type_name', 'result_name']\n",
    "    \n",
    "    if is_train:\n",
    "        scaler = StandardScaler()\n",
    "        df[feature_cols] = scaler.fit_transform(df[feature_cols].values)\n",
    "    else:\n",
    "        df[feature_cols] = scaler.transform(df[feature_cols].values)\n",
    "\n",
    "    # 4. 시퀀스 변환 (Group by Episode)\n",
    "    # 각 에피소드를 (Seq_Len, Features) 형태의 텐서로 변환하여 리스트에 저장\n",
    "    grouped = df.groupby(['game_id', 'episode_id'])\n",
    "    \n",
    "    sequences = []\n",
    "    targets = []\n",
    "    keys = [] # (game_id, episode_id) 저장\n",
    "    \n",
    "    print(f\" -> 시퀀스 변환 중... ({'Train' if is_train else 'Test'})\")\n",
    "    \n",
    "    for (game_id, episode_id), group in grouped:\n",
    "        # 입력 시퀀스 (Features)\n",
    "        seq_tensor = torch.tensor(group[feature_cols].values, dtype=torch.float32)\n",
    "        sequences.append(seq_tensor)\n",
    "        keys.append((game_id, episode_id))\n",
    "        \n",
    "        # 정답 (Target) - 마지막 행의 end_x, end_y\n",
    "        if is_train:\n",
    "            target = group[['end_x', 'end_y']].iloc[-1].values\n",
    "            targets.append(torch.tensor(target, dtype=torch.float32))\n",
    "            \n",
    "    return sequences, targets, keys, scaler, encoders, len(feature_cols)\n",
    "\n",
    "# ==============================================================================\n",
    "# [3] Dataset & Collate Function (패딩 처리)\n",
    "# ==============================================================================\n",
    "class SoccerSeqDataset(Dataset):\n",
    "    def __init__(self, sequences, targets=None):\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.targets:\n",
    "            return self.sequences[idx], self.targets[idx]\n",
    "        return self.sequences[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # 배치 내의 가변 길이 시퀀스들을 패딩하여 길이를 맞춤\n",
    "    # batch: list of (seq, target) or list of seq\n",
    "    \n",
    "    has_target = isinstance(batch[0], tuple)\n",
    "    \n",
    "    if has_target:\n",
    "        sequences = [item[0] for item in batch]\n",
    "        targets = torch.stack([item[1] for item in batch])\n",
    "    else:\n",
    "        sequences = batch\n",
    "        targets = None\n",
    "        \n",
    "    # 시퀀스 길이 정보 저장 (pack_padded_sequence용)\n",
    "    lengths = torch.tensor([len(seq) for seq in sequences])\n",
    "    \n",
    "    # 패딩 (가장 긴 시퀀스 길이에 맞춤, 나머지 0으로 채움)\n",
    "    # batch_first=True -> (Batch, Max_Seq_Len, Feat)\n",
    "    padded_seqs = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    \n",
    "    return padded_seqs, targets, lengths\n",
    "\n",
    "# ==============================================================================\n",
    "# [4] LSTM 모델 정의\n",
    "# ==============================================================================\n",
    "class SoccerLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout):\n",
    "        super(SoccerLSTM, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, \n",
    "                            batch_first=True, dropout=dropout)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 2) # end_x, end_y\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        # x: (Batch, Seq_Len, Input_Dim)\n",
    "        \n",
    "        # Pack: 패딩된 0 부분을 연산에서 제외하여 속도/정확도 향상\n",
    "        packed_input = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        # LSTM 통과\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_input)\n",
    "        \n",
    "        # Unpack은 필요 없음 (마지막 hidden state만 쓰기 때문)\n",
    "        # hidden: (Num_Layers, Batch, Hidden_Dim)\n",
    "        # 마지막 층의 hidden state 추출\n",
    "        last_hidden = hidden[-1]\n",
    "        \n",
    "        # 좌표 예측\n",
    "        out = self.fc(last_hidden)\n",
    "        return out\n",
    "\n",
    "# ==============================================================================\n",
    "# [5] 데이터 준비 및 학습\n",
    "# ==============================================================================\n",
    "print(\"1. 데이터 로드 및 시퀀스 변환...\")\n",
    "df_train = pd.read_csv(TRAIN_FILE)\n",
    "\n",
    "# Train 시퀀스 생성\n",
    "train_seqs, train_targets, _, scaler, saved_encoders, input_dim = create_sequences(df_train, is_train=True)\n",
    "\n",
    "# Dataset & DataLoader\n",
    "train_dataset = SoccerSeqDataset(train_seqs, train_targets)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# 모델 생성\n",
    "model = SoccerLSTM(input_dim, HIDDEN_DIM, NUM_LAYERS, DROPOUT).to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"2. 학습 시작 (Epochs: {EPOCHS})...\")\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for padded_seqs, targets, lengths in train_loader:\n",
    "        padded_seqs = padded_seqs.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        # lengths는 CPU에 있어도 됨 (pack_padded_sequence가 처리)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(padded_seqs, lengths)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"   Epoch [{epoch+1}/{EPOCHS}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# [6] Test 예측 및 결과 병합\n",
    "# ==============================================================================\n",
    "print(\"3. Test 데이터 처리...\")\n",
    "\n",
    "# Test 파일 로드\n",
    "test_files = []\n",
    "for root, dirs, files in os.walk(TEST_FOLDER):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            test_files.append(os.path.join(root, file))\n",
    "\n",
    "df_test_list = [pd.read_csv(f) for f in test_files]\n",
    "df_test = pd.concat(df_test_list, ignore_index=True)\n",
    "\n",
    "# Test 시퀀스 생성 (Targets=None, Keys 필요)\n",
    "test_seqs, _, test_keys, _, _, _ = create_sequences(df_test, scaler=scaler, encoders=saved_encoders, is_train=False)\n",
    "\n",
    "test_dataset = SoccerSeqDataset(test_seqs)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(\"4. 예측 수행...\")\n",
    "model.eval()\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for padded_seqs, _, lengths in test_loader:\n",
    "        padded_seqs = padded_seqs.to(DEVICE)\n",
    "        outputs = model(padded_seqs, lengths)\n",
    "        all_preds.append(outputs.cpu().numpy())\n",
    "\n",
    "predictions = np.vstack(all_preds)\n",
    "\n",
    "# Clipping\n",
    "MAX_X, MAX_Y = 105.0, 68.0\n",
    "pred_x = np.clip(predictions[:, 0], 0, MAX_X)\n",
    "pred_y = np.clip(predictions[:, 1], 0, MAX_Y)\n",
    "\n",
    "# 결과 DataFrame 생성\n",
    "# test_keys 순서대로 예측값이 나왔으므로 그대로 매칭\n",
    "result_df = pd.DataFrame(test_keys, columns=['game_id', 'episode_id'])\n",
    "result_df['pred_end_x'] = pred_x\n",
    "result_df['pred_end_y'] = pred_y\n",
    "\n",
    "# ==============================================================================\n",
    "# [7] Sample Submission 병합 (사진 기준 컬럼: game_episode)\n",
    "# ==============================================================================\n",
    "print(\"5. Sample Submission 파일 병합...\")\n",
    "\n",
    "submission = pd.read_csv(SAMPLE_FILE)\n",
    "\n",
    "# game_episode 컬럼을 쪼개서 키 생성\n",
    "submission['game_id'] = submission['game_episode'].apply(lambda x: int(x.split('_')[0]))\n",
    "submission['episode_id'] = submission['game_episode'].apply(lambda x: int(x.split('_')[1]))\n",
    "\n",
    "# 병합 (Left Join)\n",
    "final_df = pd.merge(submission, result_df, on=['game_id', 'episode_id'], how='left')\n",
    "\n",
    "# 컬럼 정리\n",
    "final_df['end_x'] = final_df['pred_end_x']\n",
    "final_df['end_y'] = final_df['pred_end_y']\n",
    "final_df = final_df.fillna(0)\n",
    "\n",
    "# 최종 저장 (game_episode, end_x, end_y)\n",
    "final_output = final_df[['game_episode', 'end_x', 'end_y']]\n",
    "final_output.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(f\"\\n[성공] '{OUTPUT_FILE}' 생성 완료.\")\n",
    "print(f\" -> 데이터 확인:\\n{final_output.head()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
